from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.chrome.service import Service
from webdriver_manager.chrome import ChromeDriverManager
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
import time
import json

# ============================================
# 1. ìì—°ê³¼í•™ëŒ€í•™ í•™ê³¼ ì •ë³´
# ============================================

NATSCI_DEPARTMENTS = {
    "ìƒëª…ê³¼í•™ê³¼": "bio",
    "ìˆ˜í•™ê³¼": "math",
    "ë¬¼ë¦¬í•™ê³¼": "physics",
    "í™”í•™ê³¼": "chem"
}

NATSCI_CURRICULUM_URL = "https://cscience.skku.edu/cscience/undergraduate/{}_curiculum.do"


# ============================================
# 2. selenium ê¸°ë³¸ ì„¤ì •
# ============================================

driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()))
driver.maximize_window()

wait = WebDriverWait(driver, 10)

# ============================================
# 3. ì•ˆì •í˜• Offset í¬ë¡¤ëŸ¬ (ì´ìˆ˜í•™ë…„ í¬í•¨)
# ============================================

def crawl_offset_curriculum(url):
    all_subjects = []
    offset = 0
    previous_titles = []

    while True:
        page_url = f"{url}?pager.offset={offset}&lang=All"
        print(f"\n=== í˜ì´ì§€ ì´ë™ offset={offset} ===")
        driver.get(page_url)

        # í…Œì´ë¸” ë¡œë”© ëŒ€ê¸°
        try:
            wait.until(EC.presence_of_element_located((By.CSS_SELECTOR, "table tbody tr")))
        except:
            print("â†’ í…Œì´ë¸” ì—†ìŒ: ì¢…ë£Œ")
            break

        rows = driver.find_elements(By.CSS_SELECTOR, "table tbody tr")

        if len(rows) == 0:
            print("â†’ í…Œì´ë¸” ì—†ìŒ: ì¢…ë£Œ")
            break

        # í˜ì´ì§€ ì œëª© ë¦¬ìŠ¤íŠ¸ ì¶”ì¶œ
        current_titles = []
        for i in range(0, len(rows), 2):
            try:
                title = rows[i].find_element(By.CSS_SELECTOR, "td:nth-child(2) a").text.strip()
                current_titles.append(title)
            except:
                pass

        # ë°˜ë³µ ê°ì§€ â†’ ì¢…ë£Œ
        if current_titles == previous_titles:
            print("â†’ ë§ˆì§€ë§‰ í˜ì´ì§€ ë„ë‹¬: ì¢…ë£Œ")
            break

        previous_titles = current_titles

        # ìƒì„¸ í¬ë¡¤ë§
        main_indices = list(range(0, len(rows), 2))

        for main_idx in main_indices:
            try:
                rows = driver.find_elements(By.CSS_SELECTOR, "table tbody tr")
                main_row = rows[main_idx]

                title_elem = main_row.find_element(By.CSS_SELECTOR, "td:nth-child(2) a")
                name = title_elem.text.strip()

                # â­ ì´ìˆ˜í•™ë…„ (7ë²ˆì§¸ ì»¬ëŸ¼)
                try:
                    grade_year = main_row.find_element(By.CSS_SELECTOR, "td:nth-child(7)").text.strip()
                except:
                    grade_year = ""

                # ìƒì„¸ë³´ê¸° í´ë¦­
                driver.execute_script("arguments[0].click();", title_elem)

                # ìƒì„¸ row ë¡œë”© ëŒ€ê¸°
                def detail_loaded(drv):
                    new_rows = drv.find_elements(By.CSS_SELECTOR, "table tbody tr")
                    if len(new_rows) <= main_idx + 1:
                        return False
                    detail_tr = new_rows[main_idx + 1]
                    return detail_tr

                detail_row = wait.until(detail_loaded)
                desc_td = detail_row.find_element(By.CSS_SELECTOR, "td")

                # â­ description ì•ˆì •ì ìœ¼ë¡œ ìˆ˜ì§‘
                desc = desc_td.get_attribute("innerText").strip()

                if desc == "":
                    time.sleep(0.2)
                    desc = desc_td.get_attribute("innerText").strip()

                if desc == "":
                    print(f"âš  ì„¤ëª… ì—†ìŒ: {name}")

                print(f"[âœ“] {name} / {grade_year} / desc_len={len(desc)}")

                all_subjects.append({
                    "grade_year": grade_year,
                    "name": name,
                    "description": desc
                })

            except Exception as e:
                print(f"âŒ ì—ëŸ¬ ë°œìƒ: {e}")
                continue

        offset += 30
        if offset > 10000:
            print("â†’ offset ë¹„ì •ìƒ ì¦ê°€: ê°•ì œ ì¢…ë£Œ")
            break

    return all_subjects


# ============================================
# 4. ì „ì²´ ìì—°ê³¼í•™ëŒ€í•™ í¬ë¡¤ë§ ì‹¤í–‰
# ============================================

result = {
    "ì„±ê· ê´€ëŒ€í•™êµ": {
        "ìì—°ê³¼í•™ëŒ€í•™": {}
    }
}

print("\n================ ìì—°ê³¼í•™ëŒ€í•™ í¬ë¡¤ë§ ì‹œì‘ ================\n")

for dept_name, code in NATSCI_DEPARTMENTS.items():

    print(f"\n========== {dept_name} ==========")
    curriculum_url = NATSCI_CURRICULUM_URL.format(code)

    subjects = crawl_offset_curriculum(curriculum_url)
    result["ì„±ê· ê´€ëŒ€í•™êµ"]["ìì—°ê³¼í•™ëŒ€í•™"][dept_name] = subjects


# JSON ì €ì¥
with open("skku_natural_science_courses_last.json", "w", encoding="utf-8") as f:
    json.dump(result, f, ensure_ascii=False, indent=4)

print("\nğŸ‰ ìì—°ê³¼í•™ëŒ€í•™ ì „ì²´ í¬ë¡¤ë§ ì™„ë£Œ!")
driver.quit()
