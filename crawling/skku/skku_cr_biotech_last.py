from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.chrome.service import Service
from webdriver_manager.chrome import ChromeDriverManager
import time
import json


# ============================================
# 1. í•™ê³¼ ì •ë³´
# ============================================

# ìƒëª…ê³µí•™ëŒ€í•™ (biotech)
BIOTECH_DEPARTMENTS = {
    "ì‹í’ˆìƒëª…ê³µí•™ê³¼": "food",
    "ë°”ì´ì˜¤ë©”ì¹´íŠ¸ë¡œë‹‰ìŠ¤í•™ê³¼": "bio"
}

BIOTECH_CURRICULUM_URL = "https://biotech.skku.edu/biotech/course/{}_curriculum.do"

# ìœµí•©ìƒëª…ê³µí•™ê³¼ (skb)
SKB_CURRICULUM_URL = "https://skb.skku.edu/gene/under/under_curriculum.do"

# ============================================
# 2. Selenium ì„¤ì •
# ============================================

driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()))
driver.maximize_window()


# ============================================
# 3. offset ê¸°ë°˜ ê³µí†µ í¬ë¡¤ëŸ¬ (SW/ICE ë°©ì‹ ê·¸ëŒ€ë¡œ)
# ============================================

from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC

def crawl_offset_curriculum(url):
    all_subjects = []
    offset = 0
    previous_titles = []

    wait = WebDriverWait(driver, 10)

    while True:
        page_url = f"{url}?pager.offset={offset}&lang=All"
        print(f"\n[í˜ì´ì§€ ì´ë™] {page_url}")

        driver.get(page_url)

        # í…Œì´ë¸”ì´ ë¡œë”©ë  ë•Œê¹Œì§€ ëŒ€ê¸°
        try:
            wait.until(EC.presence_of_element_located((By.CSS_SELECTOR, "table tbody tr")))
        except:
            print("â†’ í…Œì´ë¸” ì—†ìŒ: ì¢…ë£Œ")
            break

        rows = driver.find_elements(By.CSS_SELECTOR, "table tbody tr")
        if len(rows) == 0:
            print("â†’ í…Œì´ë¸” ì—†ìŒ: ì¢…ë£Œ")
            break

        # ì´ë²ˆ í˜ì´ì§€ì˜ ì œëª© ë¦¬ìŠ¤íŠ¸
        current_titles = []
        for i in range(0, len(rows), 2):
            try:
                title = rows[i].find_element(By.CSS_SELECTOR, "td:nth-child(2) a").text.strip()
                current_titles.append(title)
            except:
                pass

        # ì´ì „ í˜ì´ì§€ì™€ ê°™ìœ¼ë©´ ë§ˆì§€ë§‰ í˜ì´ì§€ë¡œ íŒë‹¨
        if current_titles == previous_titles:
            print("â†’ ë§ˆì§€ë§‰ í˜ì´ì§€ ë„ë‹¬: ì¢…ë£Œ")
            break

        previous_titles = current_titles

        # ===== ìƒì„¸ í¬ë¡¤ë§ =====
        # âš  rowsê°€ í´ë¦­ í›„ì— ê¹¨ì§ˆ ìˆ˜ ìˆìœ¼ë‹ˆ, ë§¤ loopë§ˆë‹¤ ë‹¤ì‹œ ê°€ì ¸ì˜¤ë„ë¡ ì„¤ê³„
        main_indices = list(range(0, len(rows), 2))

        for main_idx in main_indices:
            try:
                # ë§¤ë²ˆ ìƒˆë¡œ rowsë¥¼ ë°›ì•„ì„œ stale element ë°©ì§€
                rows = driver.find_elements(By.CSS_SELECTOR, "table tbody tr")

                main_row = rows[main_idx]

                title_elem = main_row.find_element(By.CSS_SELECTOR, "td:nth-child(2) a")
                name = title_elem.text.strip()

                # â­ ì´ìˆ˜í•™ë…„: 7ë²ˆì§¸ ì»¬ëŸ¼
                try:
                    grade_year = main_row.find_element(By.CSS_SELECTOR, "td:nth-child(7)").text.strip()
                except:
                    grade_year = ""   # ê³µë°±ì´ë©´ ê·¸ëŒ€ë¡œ ë‘ê¸°

                # ê³¼ëª©ëª… í´ë¦­ (JS ì‚¬ìš©ìœ¼ë¡œ ê°€ë ¤ì§„ ì—˜ë¦¬ë¨¼íŠ¸ ë¬¸ì œ ë°©ì§€)
                driver.execute_script("arguments[0].click();", title_elem)

                # í´ë¦­ í›„, ë°”ë¡œ ì•„ë˜ tr(ìƒì„¸ì„¤ëª… row)ì´ ì—´ë¦´ ë•Œê¹Œì§€ ëŒ€ê¸°
                def detail_row_loaded(drv):
                    new_rows = drv.find_elements(By.CSS_SELECTOR, "table tbody tr")
                    if len(new_rows) <= main_idx + 1:
                        return False
                    detail_tr = new_rows[main_idx + 1]
                    td = detail_tr.find_element(By.CSS_SELECTOR, "td")
                    text = td.get_attribute("innerText").strip()
                    # í…ìŠ¤íŠ¸ ìœ ë¬´ì™€ ìƒê´€ì—†ì´ trì´ ì¤€ë¹„ë˜ë©´ True ë¦¬í„´
                    return detail_tr

                detail_row = wait.until(detail_row_loaded)

                # ìƒì„¸ì„¤ëª… ì¶”ì¶œ (innerText ì‚¬ìš©)
                desc_td = detail_row.find_element(By.CSS_SELECTOR, "td")
                desc = desc_td.get_attribute("innerText").strip()

                # ê·¸ë˜ë„ ë¹ˆ ë¬¸ìì—´ì´ë©´ í•œë²ˆ ë” ì¬ì‹œë„ (ì•½ê°„ì˜ ë”œë ˆì´ í›„)
                if desc == "":
                    time.sleep(0.3)
                    desc_td = detail_row.find_element(By.CSS_SELECTOR, "td")
                    desc = desc_td.get_attribute("innerText").strip()

                # ì—¬ì „íˆ ë¹ˆê°’ì´ë©´ ê²½ê³  ì¶œë ¥ (ì‹¤ì œ ì„¤ëª…ì´ ì—†ì„ ê°€ëŠ¥ì„±)
                if desc == "":
                    print(f"âš  ì„¤ëª… ì—†ìŒ(ë¹ˆ ë¬¸ìì—´): {name}")

                all_subjects.append({
                    "grade_year": grade_year,
                    "name": name,
                    "description": desc
                })

                print(f"[âœ“] {name} / {grade_year} / desc_len={len(desc)}")

            except Exception as e:
                print(f"âŒ ì—ëŸ¬ ë°œìƒ (index={main_idx}): {e}")
                continue

        offset += 30
        if offset > 10000:
            print("â†’ offset ë¹„ì •ìƒ ì¦ê°€: ê°•ì œ ì¢…ë£Œ")
            break

    return all_subjects




# ============================================
# 4. ì „ì²´ ì‹¤í–‰ (Biotech + SKB)
# ============================================

result = {
    "ì„±ê· ê´€ëŒ€í•™êµ": {
        "ìƒëª…ê³µí•™ëŒ€í•™": {},
        "ìœµí•©ìƒëª…ê³µí•™ê³¼": []
    }
}

# ìƒëª…ê³µí•™ëŒ€í•™ 2ê°œ í•™ê³¼
for dept_name, code in BIOTECH_DEPARTMENTS.items():
    print(f"\n========== ìƒëª…ê³µí•™ëŒ€í•™ {dept_name} ==========")
    curriculum_url = BIOTECH_CURRICULUM_URL.format(code)
    subjects = crawl_offset_curriculum(curriculum_url)
    result["ì„±ê· ê´€ëŒ€í•™êµ"]["ìƒëª…ê³µí•™ëŒ€í•™"][dept_name] = subjects

# ìœµí•©ìƒëª…ê³µí•™ê³¼
print("\n========== ìœµí•©ìƒëª…ê³µí•™ê³¼ ==========")
skb_subjects = crawl_offset_curriculum(SKB_CURRICULUM_URL)
result["ì„±ê· ê´€ëŒ€í•™êµ"]["ìœµí•©ìƒëª…ê³µí•™ê³¼"] = skb_subjects


# JSON ì €ì¥
with open("skku_biotech_skb_courses_last.json", "w", encoding="utf-8") as f:
    json.dump(result, f, ensure_ascii=False, indent=4)

print("\nğŸ‰ ìƒëª…ê³µí•™ëŒ€í•™ + ìœµí•©ìƒëª…ê³µí•™ê³¼ ì „ì²´ í¬ë¡¤ë§ ì™„ë£Œ!")
driver.quit()
